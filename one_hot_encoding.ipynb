{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from numpy import argmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (200, 28, 28)\n",
      "y_train shape: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "argmax: 5\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST data.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train_sample = X_train[:200]\n",
    "x_test_sample = X_train[:500]\n",
    "\n",
    "# Turning the outputs into one-hot encoded representations\n",
    "y_train_one = to_categorical(y_train)\n",
    "#y_train_one = np.array([encoding.reshape(1,-1) for encoding in y_train_one]) # reshape from (10,) to (1,10)\n",
    "\n",
    "y_test_one = to_categorical(y_test)\n",
    "#y_test_one = np.array([encoding.reshape(1,-1) for encoding in y_test_one]) # reshape from (10,) to (1,10)\n",
    "\n",
    "y_train_one_sample = y_train_one[:200]\n",
    "y_test_one_sample = y_train_one_sample[:500]\n",
    "\n",
    "\n",
    "print(\"x_train shape: \" + str(x_train_sample.shape))\n",
    "print(\"y_train shape: \" + str(y_train_one_sample[0]))\n",
    "print(\"argmax: \" + str(argmax(y_train_one_sample[0]))) # use argmax to get the corresponding digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Flatten - (28, 784)\n",
      "Dense - (784, 20)\n",
      "Dense - (20, 10)\n",
      "\n",
      "(10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/sync/gw/fall2021/csci6907_neural_networks/gwu_nn/gwu_nn/loss_functions.py:60: RuntimeWarning: invalid value encountered in log\n",
      "  softmax_cross_entropy_loss = -1.0 * y_true * np.log(y_pred) - (1.0 - y_true) * np.log(1 - y_pred)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (20,1) and (10,10) not aligned: 1 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21963/1617060403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiclass_cross_entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/d/sync/gw/fall2021/csci6907_neural_networks/gwu_nn/gwu_nn/gwu_network.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/sync/gw/fall2021/csci6907_neural_networks/gwu_nn/gwu_nn/layers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moutput_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/sync/gw/fall2021/csci6907_neural_networks/gwu_nn/gwu_nn/layers.py\u001b[0m in \u001b[0;36mbackward_propagation\u001b[0;34m(self, output_error, learning_rate)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0minput_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mweights_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (20,1) and (10,10) not aligned: 1 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "#### FLAT MODEL ####\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.RandomState(1)\n",
    "\n",
    "from gwu_nn.gwu_network import GWUNetwork\n",
    "from gwu_nn.layers import Dense, Convolutional, Flatten\n",
    "\n",
    "network = GWUNetwork()\n",
    "network.add(Flatten(28,input_channels=1))\n",
    "network.add(Dense(20, activation='relu'))\n",
    "network.add(Dense(10)) # no activation, do softmax afterward\n",
    "\n",
    "# Finally to complete our model we need to compile it. This defines our loss function and learning_rate\n",
    "network.compile(loss='multiclass_cross_entropy', lr=0.001)\n",
    "print(network)\n",
    "network.fit(x_train_sample, y_train_one_sample, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict using the test set.\n",
    "raw_predictions = network.predict(x_test_sample)\n",
    "\n",
    "'''\n",
    "predictions = [round(x[0][0]) for x in raw_predictions]\n",
    "actual = [y for y in y_test_sample]\n",
    "count = 0\n",
    "for p,a in zip(predictions,actual):\n",
    "    if p == a:\n",
    "        count += 1\n",
    "print(\"accuracy: \" + str(100 * count/len(predictions)))\n",
    "\n",
    "# show figures where it messed up\n",
    "'''\n",
    "np.clip(raw_predictions,0.01,0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Convolutional - (28, 28)\n",
      "MaxPool - (28, 14)\n",
      "Flatten - (14, 196)\n",
      "Dense - (196, 40)\n",
      "Dense - (40, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### CNN MODEL ####\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.RandomState(1)\n",
    "\n",
    "from gwu_nn.gwu_network import GWUNetwork\n",
    "from gwu_nn.layers import Dense, Convolutional, Flatten, MaxPool\n",
    "\n",
    "network = GWUNetwork()\n",
    "network.add(Convolutional(input_size=28, input_channels=1, kernel_size=3, num_kernels=1, activation='relu'))\n",
    "network.add(MaxPool(28,2)) # works better without pooling\n",
    "network.add(Flatten(14,input_channels=1)) # input size = 28\n",
    "network.add(Dense(40, activation='relu'))\n",
    "network.add(Dense(1, add_bias=False, activation='sigmoid'))\n",
    "\n",
    "# Finally to complete our model we need to compile it. This defines our loss function and learning_rate\n",
    "network.compile(loss='log_loss', lr=0.001)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1   error=nan\n"
     ]
    }
   ],
   "source": [
    "network.fit(x_train_sample, y_train_sample, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.0\n"
     ]
    }
   ],
   "source": [
    "# Predict using the test set.\n",
    "raw_predictions = network.predict(x_test_sample)\n",
    "\n",
    "# calculate accuracy and show incorrect classifications\n",
    "predictions = [round(x[0][0]) for x in raw_predictions]\n",
    "count = 0\n",
    "for p,a,i in zip(predictions,y_test_sample,i_test_sample):\n",
    "    if p == a:\n",
    "        count += 1\n",
    "    else:\n",
    "        pass\n",
    "        #print(\"Prediction: \" + str(p))\n",
    "        #ax = plt.subplot()\n",
    "        #plt.imshow(X_test[i], cmap='gray')\n",
    "        #plt.show()\n",
    "        \n",
    "print(\"accuracy: \" + str(100 * count/len(predictions)))\n",
    "#print(predictions)\n",
    "#print(y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c236e0520>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print out the kernel weights \n",
    "kernel = network.layers[0].kernels.reshape(3,3)\n",
    "\n",
    "plt.imshow(kernel, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
