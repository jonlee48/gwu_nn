{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28)\n",
      "(500, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST data.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "num1 = 0\n",
    "num2 = 1\n",
    "x_train_sample = []\n",
    "y_train_sample = []\n",
    "train_samples = 200\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] == num1 or y_train[i] == num2:\n",
    "        x_train_sample.append(X_train[i])\n",
    "        y_train_sample.append(y_train[i])\n",
    "    if len(x_train_sample) >= train_samples:\n",
    "        break\n",
    "\n",
    "x_test_sample = []\n",
    "y_test_sample = []\n",
    "i_test_sample = []\n",
    "samples = 500\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    if y_test[i] == num1 or y_test[i] == num2:\n",
    "        x_test_sample.append(X_test[i])\n",
    "        y_test_sample.append(y_test[i])\n",
    "        i_test_sample.append(i)\n",
    "    if len(x_test_sample) >= samples:\n",
    "        break\n",
    "        \n",
    "print(np.array(x_train_sample).shape)\n",
    "print(np.array(x_test_sample).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Flatten - (28, 784)\n",
      "Dense - (784, 20)\n",
      "Dense - (20, 1)\n",
      "\n",
      "epoch 1/1   error=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/sync/gw/fall2021/csci6907_neural_networks/gwu_nn/gwu_nn/loss_functions.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(-np.log(y_pred)*y_true + -np.log(1-y_pred)*(1-y_true))\n",
      "/mnt/d/sync/gw/fall2021/csci6907_neural_networks/gwu_nn/gwu_nn/loss_functions.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.mean(-np.log(y_pred)*y_true + -np.log(1-y_pred)*(1-y_true))\n"
     ]
    }
   ],
   "source": [
    "#### FLAT MODEL ####\n",
    "from gwu_nn.gwu_network import GWUNetwork\n",
    "from gwu_nn.layers import Dense, Convolutional, Flatten\n",
    "\n",
    "network = GWUNetwork()\n",
    "network.add(Flatten(28,input_channels=1))\n",
    "network.add(Dense(20, activation='relu'))\n",
    "network.add(Dense(1, add_bias=False, activation='sigmoid'))\n",
    "\n",
    "# Finally to complete our model we need to compile it. This defines our loss function and learning_rate\n",
    "network.compile(loss='log_loss', lr=0.001)\n",
    "print(network)\n",
    "network.fit(x_train_sample, y_train_sample, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.6\n"
     ]
    }
   ],
   "source": [
    "# Predict using the test set.\n",
    "raw_predictions = network.predict(x_test_sample)\n",
    "\n",
    "\n",
    "predictions = [round(x[0][0]) for x in raw_predictions]\n",
    "actual = [y for y in y_test_sample]\n",
    "count = 0\n",
    "for p,a in zip(predictions,actual):\n",
    "    if p == a:\n",
    "        count += 1\n",
    "print(\"accuracy: \" + str(100 * count/len(predictions)))\n",
    "\n",
    "# show figures where it messed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Convolutional - (28, 28)\n",
      "MaxPool - (28, 14)\n",
      "Flatten - (14, 196)\n",
      "Dense - (196, 40)\n",
      "Dense - (40, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### CNN MODEL ####\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.RandomState(1)\n",
    "\n",
    "from gwu_nn.gwu_network import GWUNetwork\n",
    "from gwu_nn.layers import Dense, Convolutional, Flatten, MaxPool\n",
    "\n",
    "network = GWUNetwork()\n",
    "network.add(Convolutional(input_size=28, input_channels=1, kernel_size=3, num_kernels=1, activation='relu'))\n",
    "network.add(MaxPool(28,2)) # works better without pooling\n",
    "network.add(Flatten(14,input_channels=1)) # input size = 28\n",
    "network.add(Dense(40, activation='relu'))\n",
    "network.add(Dense(1, add_bias=False, activation='sigmoid'))\n",
    "\n",
    "# Finally to complete our model we need to compile it. This defines our loss function and learning_rate\n",
    "network.compile(loss='log_loss', lr=0.001)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1   error=nan\n"
     ]
    }
   ],
   "source": [
    "network.fit(x_train_sample, y_train_sample, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.0\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict using the test set.\n",
    "raw_predictions = network.predict(x_test_sample)\n",
    "\n",
    "# calculate accuracy and show incorrect classifications\n",
    "predictions = [round(x[0][0]) for x in raw_predictions]\n",
    "count = 0\n",
    "for p,a,i in zip(predictions,y_test_sample,i_test_sample):\n",
    "    if p == a:\n",
    "        count += 1\n",
    "    else:\n",
    "        pass\n",
    "        #print(\"Prediction: \" + str(p))\n",
    "        #ax = plt.subplot()\n",
    "        #plt.imshow(X_test[i], cmap='gray')\n",
    "        #plt.show()\n",
    "        \n",
    "print(\"accuracy: \" + str(100 * count/len(predictions)))\n",
    "print(predictions)\n",
    "print(y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fef79e8f340>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print out the kernel weights \n",
    "kernel = network.layers[0].kernels.reshape(3,3)\n",
    "\n",
    "plt.imshow(kernel, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
